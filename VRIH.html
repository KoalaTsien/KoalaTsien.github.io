<!DOCTYPE html>


<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Temporal continuity of visual attention for future gaze prediction in immersive virtual reality">
    <meta name="author" content="Jimmy Hu">
	
	
    <title>Temporal continuity of visual attention for future gaze prediction in immersive virtual reality</title>
    <!-- Bootstrap core CSS -->
    <link href="./VRIH/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="./VRIH/css/offcanvas.css" rel="stylesheet">

  </head>
	
	
  <body>
    <div class="container">
	
    <div class="jumbotron">
      <h2>Temporal continuity of visual attention for future gaze prediction in immersive virtual reality</h2>
      <p class="abstract">Visual Attention Analysis in Immersive Virtual Reality</p>
      <p iclass="authors"><a href="https://cranehzm.github.io/">Zhiming Hu</a>, Sheng Li, and Meng Gai </p>
      <p><a class="btn btn-primary" href="./VRIH/pdf/VRIH.pdf">Paper</a> </p> 
		
	</div>    
	

    <hr>

    <div>
	<h3>Abstract</h3>
	<p>
	<B>Background</B> Eye tracking technology is receiving increased attention in the field of virtual reality. 
	Specifically, future gaze prediction is crucial in pre-computation for many applications such as gaze-contingent rendering, advertisement placement, and content-based design. 
	To explore future gaze prediction, it is necessary to analyze the temporal continuity of visual attention in immersive virtual reality.
	<B>Methods</B> In this paper, the concept of temporal continuity of visual attention is presented. 
	Subsequently, an autocorrelation function method is proposed to evaluate the temporal continuity. 
	Thereafter, the temporal continuity is analyzed in both free-viewing and task-oriented conditions. 
	<B>Results</B> Specifically, in free-viewing conditions, the analysis of a free-viewing gaze dataset indicates that the temporal continuity performs well only within a short time interval. 
	A task-oriented game scene condition was created and conducted to collect users' gaze data. 
	An analysis of the collected gaze data finds the temporal continuity has a similar performance with that of the free-viewing conditions. 
	Temporal continuity can be applied to future gaze prediction and if it is good, users' current gaze positions can be directly utilized to predict their gaze positions in the future. 
	<B>Conclusions</B> The current gaze's future prediction performances are further evaluated in both free-viewing and task-oriented conditions and discover that the current gaze can be efficiently applied to the task of short-term future gaze prediction. 
	The task of long-term gaze prediction still remains to be explored.
	</p>
    </div>
		
	
    <div class="section">
      <h3>Related work</h3>
      <hr>
      <p>Our related work on gaze analysis and prediction in virtual reality:</p>
      <p><a href="https://cranehzm.github.io/DC.html">Gaze Analysis and Prediction in Virtual Reality</a></p>
	  <p><a href="https://cranehzm.github.io/DGaze.html">DGaze: CNN-Based Gaze Prediction in Dynamic Scenes</a></p>    
	  <p><a href="https://cranehzm.github.io/SGaze.html">SGaze: A Data-Driven Eye-Head Coordination Model for Realtime Gaze Prediction</a></p>
    </div>
	
    <h3>Bibtex</h3>
    <hr>
    <div class="bibtexsection">
      @article{Hu_Temporal, 
          author = {Zhiming Hu, Sheng Li, Meng Gai}, 
          title = {Temporal continuity of visual attention for future gaze prediction in immersive virtual reality}, 
          journal = {Virtual Reality & Intelligent Hardware}, 
          year = {2020},
          publisher = {CHINA SCIENCE PUBLISHING & MEDIA LTD},
          pages = {1-11},
          issn = {1673-9108},
          doi = {10.3724/SP.J.2096-5796.19.00028}
      } 
    </div>
	
	
    <hr>
      <footer>
		<p>Send feedback and questions to <a href="https://cranehzm.github.io/">Zhiming Hu</a>.</p>
        <p>Thanks to Vincent Sitzmann for his website template. Â© 2017</p>
      </footer>

    </div><!--/.container-->
  

</body></html>